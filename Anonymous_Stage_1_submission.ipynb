{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group Name: Anonymous\n",
    "\n",
    "Group members:\n",
    "\n",
    "- Shuang Jie Zhu 33432457\n",
    "\n",
    "- Kaicheng Huang 34253572\n",
    "\n",
    "- Yuhang Peng 34278818\n",
    "\n",
    "- Jingmin Zhu 34265597 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIT5226 Project\n",
    "\n",
    "## Stage 1 - Tabular Q-Learning\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two libraries (`numpy`, `matplotlib`) and one module (`random`) are utilised for stage 1 of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the TkAgg backend in matplotlib to display both plots and animations.\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.animation import FuncAnimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Environment description**\n",
    "\n",
    "A single agent operates within a grid environment where the task is to pick up the item at a randomly determined location $A$ and deliver it to a fixed target location $B$. The grid world is defined as a square grid of size $n \\times n$, with $n$ being a parameterisable dimension with a default value of 5. The agent begins at a random location on the grid and must navigate to the item location $A$, pick it up and then transport it to the target location $B$, which is fixed at the bottom right corner of the grid with coordinates $(n-1, n-1)$.\n",
    "\n",
    "##### **Assumptions for initial agent, item and target locations**\n",
    "- Initial item location cannot be the same as initial agent location.\n",
    "- Initial item location cannot be the same as target location.\n",
    "\n",
    "##### **State space**\n",
    "\n",
    "The state space for the agent consists of the following components:\n",
    "\n",
    "1. **Agent location**: The current position of the agent on the grid, which is represented as a tuple of coordinates $(y_{agent},x_{agent})$.\n",
    "2. **Item location**: The location of the item on the grid, which is represented as a tuple of coordinates $(y_{item},x_{item})$.\n",
    "3. **Item possession status**: A boolean value indicates whether the agent has picked up the item, which is represent by a boolean variable $has\\_item$.\n",
    "\n",
    "Thus, the complete state of the environment can be represented as a tuple $\\left((y_{agent},x_{agent}), (y_{item},x_{item}), has\\_item\\right)$.\n",
    "\n",
    "##### **Action space**\n",
    "\n",
    "The agent has four actions that it can execute:\n",
    "- **Move north**: The agent attempts to move one cell upwards on the grid.\n",
    "- **Move south**: The agent attempts to move one cell downwards on the grid.\n",
    "- **Move west**: The agent attempts to move one cell to the left on the grid.\n",
    "- **Move east**: The agent attempts to move one cell to the right on the grid.\n",
    "\n",
    "These actions are executed with boundary checks to ensure that the agent does not move outside the grid.\n",
    "\n",
    "##### **Reward structure**\n",
    "\n",
    "In reinforcement learning, the reward structure is designed to encourage the agent to complete the task of picking up the item at location $A$ and delivering it to location $B$ efficiently. The reward structure is designed as follows:\n",
    "\n",
    "- **Step penalty**: The agent receives a penalty of -1 for each step it takes. This encourages the agent to complete the task in as few steps as possible.\n",
    "- **Hit-wall penalty**: The agent receives a penalty of -5 for each time it hits a wall. This encourages the agent not to get out the grid.\n",
    "- **Item pickup**: When the agent successfully reaches the item location $A$ and picks up the item, it continues to receive the step penalty of -1. No additional reward is given for picking up the item as it is part of the task. A small reward can be given to the agent in a practical application, which is not applied in the current setting.\n",
    "- **Task completion**: The agent receives a reward of +100 upon successfully deliverying the item to the target location $B$, which indicates the completion of the task.\n",
    "\n",
    "The environment and reward structure are set up to reinforce the agent's learning of an optimal policy that minimise the number of steps taken to complete the task. The agent need balance between exploring the grid to find the item and exploiting its knowledge to arrive the target location as quickly as possible once the item being picked up.\n",
    "\n",
    "The environment is implemented in Python as a class `GridWorld`, which supports grids of arbitrary size. The grid size and target location are parameterised, allowing the environment to be easily adapted to different scenarios. The movements of the agent are controlled through the `step` function, which updates the environment based on the action taken and returns the new state, the reward for the action and a boolean value indicating whether the task is completed. The environment also includes a `reset` function, which randomises the agent and item location, allowing the agent to start the task from different initial locations, promoting generalisation during its learning process.\n",
    "\n",
    "This setup provides a clear and efficient framework for the agent to learn the task of picking up and transporting an item within a grid world environment. The reward structure is designed to be simple yet effective, encouraging the agent to learn an optimal path from any starting position to the target location via the item location. The flexibility of the design of the environment allows for easy adjustments to grid size and task complexity, making it a robust foundation for further experimentation and learning in reinforcement learning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridWorld class defines the grid world environment\n",
    "class GridWorld:\n",
    "    # Define the grid world environment with default size 5x5 and target location at the bottom-right corner\n",
    "    # The agent and item locations are randomly initialised unless given_location is set to True (this is for testing phase)\n",
    "    def __init__(self, size=5, target_location=None, initial_agent_location=(0,0), initial_item_location=(0,1), given_location=False):\n",
    "        self.size = size\n",
    "        self.target_location = target_location if target_location else (size-1, size-1)\n",
    "        # If the agent and item locations are given, then use them, otherwise randomly initialise them\n",
    "        if given_location == False:\n",
    "            self.reset()\n",
    "        else:\n",
    "            self.agent_location = initial_agent_location\n",
    "            self.item_location = initial_item_location\n",
    "            self.has_item = False\n",
    "\n",
    "    # Reset the grid world environment to the initial state\n",
    "    def reset(self):\n",
    "        # Randomly initialise the agnet position in the grid and agent location can be the same as the target location\n",
    "        self.agent_location = self._random_position()\n",
    "        \n",
    "        # Randomly initialise the item position in the grid and ensure it is not at the target location or agent location\n",
    "        self.item_location = self._random_position()\n",
    "        while self.item_location == self.target_location or self.item_location == self.agent_location:\n",
    "            self.item_location = self._random_position()\n",
    "        \n",
    "        # The agent doesn't have the item initially\n",
    "        self.has_item = False\n",
    "\n",
    "        # Return the initial state\n",
    "        return self._get_state()\n",
    "\n",
    "    # Generate a random position in the grid\n",
    "    def _random_position(self):\n",
    "        return (random.randint(0, self.size-1), random.randint(0, self.size-1))\n",
    "\n",
    "    # Get the current state of (agent_location, item_location, has_item) as a tuple\n",
    "    def _get_state(self):\n",
    "        return (self.agent_location, self.item_location, self.has_item)\n",
    "\n",
    "    # Execute an action, then return the next state, reward, and whether the task is finished.\n",
    "    def step(self, action):\n",
    "        # Get the current agent location (y, x)\n",
    "        y, x = self.agent_location\n",
    "\n",
    "        # Define the action to move the agent in the four directions\n",
    "        if action == 'north':\n",
    "            new_y, new_x = y - 1, x\n",
    "        elif action == 'south':\n",
    "            new_y, new_x = y + 1, x\n",
    "        elif action == 'west':\n",
    "            new_y, new_x = y, x - 1\n",
    "        elif action == 'east':\n",
    "            new_y, new_x = y, x + 1\n",
    "        else:\n",
    "            raise ValueError(\"Invalid action!\")\n",
    "\n",
    "         # Move the agent to the new location only if it is within the grid\n",
    "        if 0 <= new_x < self.size and 0 <= new_y < self.size:\n",
    "            # Update the agent location to the new location (new_y, new_x)\n",
    "            self.agent_location = (new_y, new_x)\n",
    "            wall_hit = False\n",
    "        # Else keep the agent in place and label it as hitting the wall\n",
    "        else:\n",
    "            wall_hit = True\n",
    "\n",
    "        # If the agent reached the item location, pick up the item\n",
    "        if not self.has_item and self.agent_location == self.item_location:\n",
    "            reward = -1\n",
    "            self.has_item = True\n",
    "        # Else if the agent reached the target location with the item, reward the agent with +100 and finish the task \n",
    "        elif self.has_item and self.agent_location == self.target_location:\n",
    "            reward = 100\n",
    "            done = True\n",
    "            return self._get_state(), reward, done\n",
    "        # Else check if the agent hit the wall\n",
    "        elif wall_hit:\n",
    "            reward = -5       # Small penalty for hitting the wall\n",
    "            wall_hit = False  # Reset wall_hit after applying the penalty\n",
    "        # Else a step penalty of -1 is given\n",
    "        else:\n",
    "            reward = -1\n",
    "        \n",
    "        done = False  # Task is not finished yet\n",
    "        return self._get_state(), reward, done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Q-learning Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, a table-based Q-learning algorithm is implemented in a Python class `QLearningAgent` for an agent to complete a transport task in a grid world environment. Q-learning is an off-policy reinforcement learning algorithm that aims to find the optimal action-selection policy by learning the action-value function $Q(S,A)$, where $S$ and $A$ represent state and action, respectively. The action-value function estimates the expected cumulative reward for taking an action $A$ in state $S$ and following the optimal policy thereafter. The key idea of the algorithm is to iteratively update the Q-value based on the agent's experiences regarding the environment.\n",
    "\n",
    "##### **Key components**\n",
    "\n",
    "1. **Initialisation**:\n",
    "\n",
    "The Q-value are stored in a table (`self.q_table`), which is implemented as a Python dictionary where the keys are state-action pairs and the values are the corresponding Q-values. The agent is initialised with parameters for the learning rate (lr), discount factor (gamma), exploration rate (epsilon), exploration decay rate (epsilon_decay) and minimum exploration rate (min_epsilon).\n",
    "\n",
    "2. **Q-value retrieval**:\n",
    "\n",
    "The function `get_q_value` retrieves the Q-value for a given state-action pair. If the Q-value does not exist in the table, it is initialised to zero to ensure that all posiible state-action pairs are accounted for during the learning process.\n",
    "\n",
    "3. **Action selection**:\n",
    "\n",
    "The function `choose_action` employs an $\\epsilon$-greedy policy for th agent to select actions. With probability $\\epsilon$, the agent explores by choosing a random action. Otherwise, it exploits its current knowledge by selecting the action with the highest Q-value with probability $1-\\epsilon$. The Q-value for all possible actions in the current state are evaluated and the action(s) with the maximum Q-value are identified. If multiple actions have the same maximum Q-values, one is selected randomly to avoid bias and promote exploration.\n",
    "\n",
    "4. **Q-value update**:\n",
    "\n",
    "The Q-value for a given state-action pair is updated using the function `update_q_value` based on the reward received and the maximum Q-value of the subsequent state (if it is not terminal). The standard Q-learning update rule is adopted, which can be written as:\n",
    "\n",
    "\\begin{equation}\n",
    " Q(S,A) \\leftarrow Q(S,A) + \\alpha \\left( R + \\gamma \\max\\limits_{A'} Q(S', A') - Q(S, A)  \\right)，\n",
    "\\end{equation}\n",
    "\n",
    "where $\\alpha$ is the learning rate, determining how much new knowledge overrides the old one. The variable $R$ is the reward received after take action $A$ in state $S$. The variable $\\gamma$ is the discount factor, which controls the importance of future rewards. The term $\\max\\limits_{A'} Q(S', A')$ is the maximum Q-value for the next state $S'$, representing the best future value.\n",
    "\n",
    "It is important to point out that the Q-value is updated solely based on the immediate reward $R$ if the episode ends ($done$ is $Ture$), since there are no future states to consider.\n",
    "\n",
    "5. **Exploration rate decay**:\n",
    "\n",
    "The function `decay_exploration` models the exploration rate $\\epsilon$ is decayed multiplicateively by a factor (epsilon_decay) after each episode. This gradual reduction in exploration allows the agent to transition from exploration to exploitation as it learns more about the environment. The exploration rate is calmped to a minimum value (min_epsilon) to ensure that the agent retains some level of exploration throughout the learning process.\n",
    "\n",
    "The implemented Q-learning algorithm is designed to enable the agent to efficiently learn an optimal policy for the transport task in the grid world environment. By balancing exploration and exploitation through the $\\epsilon$-greedy policy and using the Q-value updates to iteratively improve its knowledge, the agent can learn to complete the task with minimal steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QLearningAgent defines the agent Q-learning algorithm\n",
    "class QLearningAgent:\n",
    "    # Define the Q-learning algorithm for the agent with default parameters\n",
    "    def __init__(self, actions, learning_rate=0.1, discount_factor=0.95,\n",
    "                 exploration_rate=1.0, exploration_decay=0.95, min_exploration_rate=0.01):\n",
    "        self.actions = actions  # Possible actions\n",
    "        self.lr = learning_rate  # Learning rate\n",
    "        self.gamma = discount_factor  # Discount factor\n",
    "        self.epsilon = exploration_rate  # Exploration rate (epsilon)\n",
    "        self.epsilon_decay = exploration_decay  # Exploration decay rate\n",
    "        self.min_epsilon = min_exploration_rate  # Minimum exploration rate value\n",
    "        self.q_table = {}  # Initialise the Q-table as a dictionary\n",
    "    \n",
    "    # Get the Q-value for a state-action pair \n",
    "    def get_q_value(self, state, action):\n",
    "        # Initialise Q-value to 0.0 if it doesn't exist.\n",
    "        if (state, action) not in self.q_table:\n",
    "            self.q_table[(state, action)] = 0.0\n",
    "        return self.q_table[(state, action)]\n",
    "    \n",
    "    # Choose an action based on the epsilon-greedy policy\n",
    "    def choose_action(self, state):\n",
    "        # Exploration with probability epsilon\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            return random.choice(self.actions)\n",
    "        # Else exploitation with probability 1 - epsilon\n",
    "        else:\n",
    "            q_values = [self.get_q_value(state, action) for action in self.actions]\n",
    "            max_q_value = max(q_values)\n",
    "            best_actions = [action for action, q_value in zip(self.actions, q_values) if q_value == max_q_value]\n",
    "            return random.choice(best_actions) # Randomly choose one of the best actions to expliot\n",
    "\n",
    "    # Update the Q-value for a state-action pair based on the reward and next state\n",
    "    def update_q_value(self, state, action, reward, next_state, done):\n",
    "        current_q_value = self.get_q_value(state, action)\n",
    "        # If the next state is terminal (done), the Q-value is only based on the reward\n",
    "        if done:\n",
    "            td_target = reward\n",
    "        # Else update the Q-value based on the reward and the maximum Q-value of the next state\n",
    "        else:\n",
    "            next_q_values = [self.get_q_value(next_state, next_action) for next_action in self.actions]\n",
    "            td_target = reward + self.gamma * max(next_q_values)\n",
    "        \n",
    "        td_error = td_target - current_q_value\n",
    "        self.q_table[(state, action)] = current_q_value + self.lr * td_error\n",
    "\n",
    "    # Decay the exploration rate after each episode for the purpose of exploration-exploitation trade-off\n",
    "    def decay_exploration(self):\n",
    "        self.epsilon = max(self.min_epsilon, self.epsilon * self.epsilon_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Training Phase\n",
    "\n",
    "The training process is implemented in the function `train_agent`, which trians the agent over a default of 1000 episodes. \n",
    "\n",
    "##### **Key components**\n",
    "\n",
    "1. **Episode initialisation**:\n",
    "\n",
    "At the start of each episode, the environment is reset using the `env.reset()` method, which randomises the initial agent location and the initial item location. The initial state of the environment is returned. A boolean variable $done$ is initialised to $False$, indicating that the episode is not yet finished.\n",
    "\n",
    "2. **Agent-environment interaction**:\n",
    "\n",
    "Within each episode, the agent interacts with the environment until it successfully completes the task by delivery the item to the target location  $B$. The agent selects an action using the `choose_action(state)` method, which follows an $\\epsilon$-greedy policy to balance exploration and exploitation. The selected action is executed in the environment using `env.step(action)`, which returns the next state, the reward received, and whether the episode is done.\n",
    "\n",
    "3. **Q-value update**:\n",
    "\n",
    "After executing an action, the agent updates the Q-value for the state-action pair using the `update_q_value(state, action, reward, next_state, done)` method. This update is based on the Q-learning update rule as shown in Equation (1). The state is then updated to the new state returned by the environment and the loop continues until the task is completed.\n",
    "\n",
    "4. **Exploration rate decay**:\n",
    "After each episode, the agent’s exploration rate  $\\epsilon$  is decayed using the `decay_exploration()` method. This gradual reduction in exploration allows the agent to increasingly exploit its learned policy as it gains more experience.\n",
    "\n",
    "5. **Progress monitoring**:\n",
    "\n",
    "To monitor the training progress, the code prints out a message every 1000 episodes, indicating the completion of that episode and the current value of  $\\epsilon$ to help in tracking how the exploration rate evolves over time and ensure that the training process is proceeding as expected.\n",
    "\n",
    "6. **Post-training insights (Optional)**:\n",
    "\n",
    "After training, optional code snippets are provided to print the learned Q-values for each state-action pair and the size of the Q-table. These insights can be helpful in understanding the extent of the agent’s learning and the complexity of the learned policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the agent with a default of 1000 episodes\n",
    "def train_agent(agent, env, episodes=1000):\n",
    "    for episode in range(episodes):\n",
    "        # Reset the environment for each new episode\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "    \n",
    "        # Agent continue until the task is finished\n",
    "        while not done:\n",
    "            action = agent.choose_action(state)  # Agent chooses an action\n",
    "            next_state, reward, done = env.step(action)  # Execute the action in the environment\n",
    "        \n",
    "            # Update the Q-value based on the reward received and the new state\n",
    "            agent.update_q_value(state, action, reward, next_state, done)\n",
    "        \n",
    "            # Update to the next state\n",
    "            state = next_state\n",
    "\n",
    "        # Decay the exploration rate after each episode\n",
    "        agent.decay_exploration()\n",
    "\n",
    "        # Print the progress every 1000 episodes\n",
    "        # if (episode + 1) % 1000 == 0:\n",
    "        #     print(f'Episode {episode + 1}/{episodes} completed. Epsilon: {agent.epsilon:.3f}')\n",
    "\n",
    "    # Print the learned Q-values\n",
    "    # for state, actions in agent.q_table.items():\n",
    "    #    print(f'State: {state}, Q-values: {actions}')\n",
    "\n",
    "    # Print the size of the Q-table\n",
    "    # print(f\"Q-Table Size: {len(agent.q_table)} entries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evaluation Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### **Introduction**\n",
    "In this project, our goal is to implement a tabular Q-learning algorithm to enable an agent to effectively complete a specified task in a grid world environment. The agent's task is to start from a random position, pick up an item located at point A, and deliver it to point B. To evaluate the agent's learning and generalization abilities, we designed two tests: the first test assesses the model's performance with different numbers of training episodes, the second test evaluates the performance of a model trained extensively across all possible initial states.\n",
    "\n",
    "Our objectives in conducting these tests are as follows:\n",
    "\n",
    "##### **1. Verifying the model's learning ability**\n",
    "- **Objective**: Through the first test, we can verify the model's learning ability under different training conditions. Theoretically, as the number of training episodes increases, the model should be able to better learn the optimal strategy for completing the task.\n",
    "\n",
    "- **Expected outcome**: By analysing the success rate, average steps, average reward, and deviation from the optimal strategy, we can verify whether increasing the training episodes indeed leads to improved performance. If the test results show improvement in these metrics as the number of training episodes increases, it indicates that the model's learning ability has been enhanced.\n",
    "\n",
    "##### **2. Verifying the model's generalisation ability**\n",
    "- **Objective**: Through the second test, we can verify the performance of the trained model under different initial conditions.\n",
    "\n",
    "- **Expected outcome**: If the test results show that the model maintains a high success rate and low average steps and deviation under all possible initial states, it indicates that the model has strong generalisation ability. This means that the model not only performs well under specific training conditions but can also effectively complete tasks in varying environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the Manhattan distance between two points, which is used to calculate the optimal steps\n",
    "def manhattan_distance(point1, point2):\n",
    "    return abs(point1[0] - point2[0]) + abs(point1[1] - point2[1])\n",
    "\n",
    "# Function to test the agent in the environment for a certain number of episodes with default 100 random episodes.\n",
    "# The stepa_verbose parameter is used to control printing the details of each step in the episode.\n",
    "def test_agent(agent, env, episodes=100, step_verbose=True):\n",
    "    # Initialise the metrics to calculate the overall performance\n",
    "    success_count = 0.0\n",
    "    total_steps = 0.0\n",
    "    total_reward = 0.0\n",
    "    total_deviation = 0.0\n",
    "    total_deviation_rate = 0.0\n",
    "\n",
    "    # Test the agent for the specified number of episodes\n",
    "    for episode in range(episodes):\n",
    "        # Reset the environment to for each new episode\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        episode_steps = 0\n",
    "        episode_reward = 0\n",
    "\n",
    "        # Initial positions\n",
    "        initial_agent_location = state[0]\n",
    "        initial_item_location = state[1]\n",
    "        drop_off_location = env.target_location\n",
    "\n",
    "        # Calculate theoretical shortest path or optimal steps\n",
    "        optimal_steps_to_item = manhattan_distance(initial_agent_location, initial_item_location)\n",
    "        optimal_steps_to_target = manhattan_distance(initial_item_location, drop_off_location)\n",
    "        optimal_steps = optimal_steps_to_item + optimal_steps_to_target\n",
    "\n",
    "        if step_verbose == True:\n",
    "            print(f\"\\n--- Episode {episode + 1} ---\")\n",
    "            print(f\"Initial Agent Location: {initial_agent_location}\")\n",
    "            print(f\"Initial Item Location (A): {initial_item_location}\")\n",
    "            print(f\"Drop-Off Location (B): {drop_off_location}\")\n",
    "\n",
    "        # Agent continues until the task is finished\n",
    "        while not done:\n",
    "            action = agent.choose_action(state)  # Agent selects the best action based on learned Q-values\n",
    "            next_state, reward, done = env.step(action)  # Execute the action in the environment\n",
    "            \n",
    "            episode_steps += 1\n",
    "            episode_reward += reward\n",
    "            state = next_state\n",
    "\n",
    "            if step_verbose == True:\n",
    "                # Print the step details\n",
    "                print(f\"Step {episode_steps}: Action = {action}, Reward = {reward}, New State = {next_state}\")\n",
    "\n",
    "        # Calculate the deviation from the optimal steps, total deviation, total steps, and total reward\n",
    "        deviation = episode_steps - optimal_steps\n",
    "        deviation_rate = deviation / optimal_steps \n",
    "        total_deviation += deviation\n",
    "        total_deviation_rate += deviation_rate\n",
    "        total_steps += episode_steps\n",
    "        total_reward += episode_reward\n",
    "\n",
    "        # Count the number of successful episodes where the agent delivers the item to the target location\n",
    "        if done and state[0] == env.target_location and state[2] is True:\n",
    "            success_count += 1\n",
    "\n",
    "        if step_verbose == True:\n",
    "            # Print the summary of the episode\n",
    "            print(f\"Episode {episode + 1} Summary: Steps = {episode_steps} (Optimal Steps = {optimal_steps}), Total Reward = {episode_reward}, Deviation from Optimal: {deviation}\")\n",
    "\n",
    "    success_rate = success_count / episodes\n",
    "    average_steps = total_steps / episodes\n",
    "    average_reward = total_reward / episodes\n",
    "    average_reward_per_step = total_reward / total_steps / episodes\n",
    "    average_deviation = total_deviation / episodes\n",
    "    average_deviation_rate = total_deviation_rate / episodes\n",
    "\n",
    "    if step_verbose == True:\n",
    "        # Print the overall metrics after all test episodes\n",
    "        print(\"\\n--- Overall Performance Metrics ---\")\n",
    "        print(f'Success Rate: {success_rate * 100:.2f}%')\n",
    "        print(f'Average Steps to Completion: {average_steps:.2f}')\n",
    "        print(f'Average Reward: {average_reward:.2f}')\n",
    "        print(f'Average Reward per Step: {average_reward_per_step:.2f}')\n",
    "        print(f'Average Deviation from Optimal: {average_deviation:.2f}')\n",
    "        print(f'Average Deviation Rate: {average_deviation_rate:.2f}%')\n",
    "\n",
    "    return {\n",
    "        'success_rate': success_rate * 100,\n",
    "        'average_steps': average_steps,\n",
    "        'average_reward': average_reward,\n",
    "        'average_deviation_rate': average_deviation_rate\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Test 1: Evaluating model performance with different training episodes**\n",
    "To evaluate how the number of training episodes affects model performance, we designed and conducted the following experiment:\n",
    "\n",
    "##### **Code implementation**\n",
    "In this experiment, we set different numbers of training episodes, including 1500, 2500, 3500, 4500 episodes. We then conducted 5 tests for each model and repeated the tests 5 times, calculating the mean and standard deviation of the following metrics:\n",
    "\n",
    "- **Success Rate**: The success rate indicates the percentage of trials where the agent successfully completes the task, usually expressed as a percentage. It reflects the overall effectiveness of the model.\n",
    "\n",
    "- **Average Steps**: Average steps represent the number of steps the agent takes to complete the task from the initial position. This metric reflects the efficiency of the agent in executing the task—the fewer steps, the better the path found by the agent.\n",
    "\n",
    "- **Average Reward**: Average reward represents the total average reward the agent accumulates during the task. This metric reflects the effectiveness of the agent's strategy, with higher rewards indicating more effective behaviour.\n",
    "\n",
    "- **Average Deviation Rate from Optimal**: This metric represents the average difference between the agent's actual path and the theoretically optimal path, reflecting the optimisation of the agent's strategy. The smaller the deviation, the closer the agent's strategy is to the optimal solution. The calculation formula is given as\n",
    "\n",
    "\\begin{equation*}\n",
    "\\frac{{\\text{actual steps} - \\text{optimal steps}}}{{\\text{optimal steps}}}.\n",
    "\\end{equation*}\n",
    "\n",
    "By plotting these metrics against the number of training episodes, we can visually observe the impact of training episodes on model performance.\n",
    "\n",
    "\n",
    "\n",
    "##### **Explanation**\n",
    "\n",
    "1. We chose to start with 1500 episodes because using 10 to 500 episodes often resulted in excessively long test times. Although we could eventually obtain results, the stability of those results could not be guaranteed.\n",
    "\n",
    "2. The reason for introducing the \"Average Deviation Rate from Optimal\" metric is that the other three metrics have their own limitations. The Success Rate does not adequately reflect the intelligence of the agent. Due to varying initial states, both Average Steps and Average Reward can also show inconsistencies. Therefore, we designed the Average Deviation Rate from Optimal metric, expressed as a ratio, to capture the degree of deviation between the agent’s actions and the optimal actions. This metric provides a better reflection of the agent’s intelligence.\n",
    "\n",
    "3. In a single epoch, we conducted multiple tests (test_episodes) and repeated the training and testing across multiple epochs (num_repeats). This approach was taken to minimise the impact of random initial states on the results and to more accurately measure how the model’s performance trends with training.\n",
    "\n",
    "4. One possible testing method is to use a fixed initial state to compare the metrics corresponding to different training levels (training episodes). However, after careful consideration, we discontinued this approach because it only reflects changes in the model under a single initial state, which differs from our actual requirement for the model (i.e., solving the task independently of the location of A)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_episodes_list = [1500, 2500, 3500, 4500]\n",
    "\n",
    "test_episodes = 5\n",
    "num_repeats = 5\n",
    "\n",
    "# Set up the environment and agent actions\n",
    "env = GridWorld(size=5)\n",
    "actions = ['north', 'south', 'west', 'east']\n",
    "\n",
    "# Dictionary to store results\n",
    "results = {\n",
    "    'training_episodes': [],\n",
    "    'success_rate_mean': [],\n",
    "    'success_rate_std': [],\n",
    "    'average_steps_mean': [],\n",
    "    'average_steps_std': [],\n",
    "    'average_reward_mean': [],\n",
    "    'average_reward_std': [],\n",
    "    'average_deviation_rate_mean': [],\n",
    "    'average_deviation_rate_std': []\n",
    "}\n",
    "\n",
    "# Run the experiment for different training episodes\n",
    "for training_episodes in training_episodes_list:\n",
    "    success_rates = []\n",
    "    average_steps = []\n",
    "    average_rewards = []\n",
    "    average_deviations = []\n",
    "    \n",
    "    # Repeat the experiment for each training episode\n",
    "    for _ in range(num_repeats):\n",
    "        agent = QLearningAgent(actions)  # Reinitialise the agent for each training run\n",
    "        train_agent(agent, env, training_episodes)\n",
    "        metrics = test_agent(agent, env, episodes=test_episodes, step_verbose=False)\n",
    "        # print(metrics)\n",
    "        \n",
    "        # Store individual test results\n",
    "        success_rates.append(metrics['success_rate'])\n",
    "        average_steps.append(metrics['average_steps'])\n",
    "        average_rewards.append(metrics['average_reward'])\n",
    "        average_deviations.append(metrics['average_deviation_rate'])\n",
    "    \n",
    "    # Store mean and standard deviation of results\n",
    "    results['training_episodes'].append(training_episodes)\n",
    "    results['success_rate_mean'].append(np.mean(success_rates))\n",
    "    results['success_rate_std'].append(np.std(success_rates))\n",
    "    results['average_steps_mean'].append(np.mean(average_steps))\n",
    "    results['average_steps_std'].append(np.std(average_steps))\n",
    "    results['average_reward_mean'].append(np.mean(average_rewards))\n",
    "    results['average_reward_std'].append(np.std(average_rewards))\n",
    "    results['average_deviation_rate_mean'].append(np.mean(average_deviations))\n",
    "    results['average_deviation_rate_std'].append(np.std(average_deviations))\n",
    "\n",
    "# Plotting results with error bars\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.suptitle('Test 1. Model Performance with Different Training Episodes', fontsize=16)\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.errorbar(results['training_episodes'], results['success_rate_mean'], \n",
    "             yerr=np.array(results['success_rate_std']) * 0.1, fmt='-o', ecolor='red', capsize=5)\n",
    "plt.title('Success Rate')\n",
    "plt.xlabel('Training Episodes')\n",
    "plt.ylabel('Success Rate (%)')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.errorbar(results['training_episodes'], results['average_steps_mean'], \n",
    "             yerr=np.array(results['average_steps_std']) * 0.1, fmt='-o', ecolor='red', capsize=5)\n",
    "plt.title('Average Steps to Completion')\n",
    "plt.xlabel('Training Episodes')\n",
    "plt.ylabel('Average Steps')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.errorbar(results['training_episodes'], results['average_reward_mean'], \n",
    "             yerr=np.array(results['average_reward_std']) * 0.1, fmt='-o', ecolor='red', capsize=5)\n",
    "plt.title('Average Reward')\n",
    "plt.xlabel('Training Episodes')\n",
    "plt.ylabel('Average Reward')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.errorbar(results['training_episodes'], results['average_deviation_rate_mean'], \n",
    "             yerr=np.array(results['average_deviation_rate_std']) * 0.1, fmt='-o', ecolor='red', capsize=5)\n",
    "plt.title('Average Deviation Rate from Optimal')\n",
    "plt.xlabel('Training Episodes')\n",
    "plt.ylabel('Average Deviation')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the test results, we can observe that as the number of training episodes increases, the model's Average Steps and Average Deviation Rate from Optimal consistently decrease, while the Average Reward steadily increases. This clearly demonstrates that the capability of the agent we designed improves with more training and approaches optimal performance. It can be seen that after approximately 3000 training episodes, the model's performance is already very close to optimal performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Test 2: Evaluating the performance of a model trained extensively across all initial states**\n",
    "In the second test, we selected a model trained with 50000 episodes and evaluated its performance across all possible initial states. Specifically, we traversed all possible combinations of the agent's initial position and the item's position, measuring the model's performance in these scenarios.\n",
    "\n",
    "#### **Code implementation**\n",
    "To cover all possible initial states, we traversed each possible agent starting position and item position in a 5x5 grid and conducted multiple tests for each state. We recorded the success rate, average steps, average reward, and deviation rate from the optimal strategy, and the corresponding means and standard deviations are provided. It is worth pointing out that we exclude cases where the initial item position is the same as the initial agent position, and the initial item position is the same as the target location according to the assumptions.\n",
    "\n",
    "#### **Capability assessment**\n",
    "The purpose of this test is to evaluate whether the model, after extensive training, can perform well across all initial states. This is crucial for assessing the model's generalisation ability: whether it can successfully complete the task and achieve high rewards regardless of the initial conditions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Summary over 5 Repeats of 5 Test Episodes ---\n",
      "success_rate: 100.0 +/- 0.0\n",
      "average_steps: 7.54 +/- 0.94\n",
      "average_reward: 93.42 +/- 0.96\n",
      "average_deviation_rate: 0.01 +/- 0.02\n"
     ]
    }
   ],
   "source": [
    "# Training parameters\n",
    "training_episodes = 50000  # Number of training episodes, adjust as needed\n",
    "test_episodes = 5 # Number of test episodes per configuration\n",
    "num_repeats = 5  # Number of repeats per initial configuration\n",
    "\n",
    "# Grid size\n",
    "grid_size = 5\n",
    "\n",
    "# Set up the environment and agent actions\n",
    "env = GridWorld(size=grid_size)\n",
    "actions = ['north', 'south', 'west', 'east']\n",
    "\n",
    "# Initialise the agent and train\n",
    "agent = QLearningAgent(actions)\n",
    "train_agent(agent, env, training_episodes)\n",
    "\n",
    "# Initialise dictionaries to store results\n",
    "results = {\n",
    "    'initial_states': [],\n",
    "    'success_rate_mean': [],\n",
    "    'success_rate_std': [],\n",
    "    'average_steps_mean': [],\n",
    "    'average_steps_std': [],\n",
    "    'average_reward_mean': [],\n",
    "    'average_reward_std': [],\n",
    "    'average_deviation_rate_mean': [],\n",
    "    'average_deviation_rate_std': []\n",
    "}\n",
    "\n",
    "# Iterate over all possible initial states (agent's start position and item's position)\n",
    "for start_x in range(grid_size):\n",
    "    for start_y in range(grid_size):\n",
    "        for item_x in range(grid_size):\n",
    "            for item_y in range(grid_size):\n",
    "                success_rates = []\n",
    "                average_steps = []\n",
    "                average_rewards = []\n",
    "                average_deviations = []\n",
    "\n",
    "                initial_agent_pos = (start_x, start_y)\n",
    "                initial_item_pos = (item_x, item_y)\n",
    "                if initial_agent_pos == initial_item_pos:\n",
    "                    continue\n",
    "                if initial_agent_pos == env.target_location or initial_item_pos == env.target_location:\n",
    "                    continue\n",
    "                    \n",
    "                # Repeat the test multiple times for each initial state\n",
    "                for _ in range(num_repeats):\n",
    "              \n",
    "                    env = GridWorld(size=5, initial_agent_location= initial_agent_pos, initial_item_location= initial_item_pos, given_location = True )\n",
    "                    metrics = test_agent(agent, env, episodes=test_episodes ,step_verbose=False)\n",
    "                    \n",
    "                    # Store individual test results\n",
    "                    success_rates.append(metrics['success_rate'])\n",
    "                    average_steps.append(metrics['average_steps'])\n",
    "                    average_rewards.append(metrics['average_reward'])\n",
    "                    average_deviations.append(metrics['average_deviation_rate'])\n",
    "                \n",
    "                # Store the mean and standard deviation of results\n",
    "\n",
    "                results['success_rate_mean'].append(np.mean(success_rates))\n",
    "                results['success_rate_std'].append(np.std(success_rates))\n",
    "                results['average_steps_mean'].append(np.mean(average_steps))\n",
    "                results['average_steps_std'].append(np.std(average_steps))\n",
    "                results['average_reward_mean'].append(np.mean(average_rewards))\n",
    "                results['average_reward_std'].append(np.std(average_rewards))\n",
    "                results['average_deviation_rate_mean'].append(np.mean(average_deviations))\n",
    "                results['average_deviation_rate_std'].append(np.std(average_deviations))\n",
    "\n",
    "print(f\"\\n--- Final Summary over {num_repeats} Repeats of {test_episodes} Test Episodes ---\")\n",
    "print(f\"success_rate: {np.mean(results['success_rate_mean']).round(2)} +/- {np.mean(results['success_rate_std']).round(2)}\")\n",
    "print(f\"average_steps: {np.mean(results['average_steps_mean']).round(2)} +/- {np.mean(results['average_steps_std']).round(2)}\")\n",
    "print(f\"average_reward: {np.mean(results['average_reward_mean']).round(2)} +/- {np.mean(results['average_reward_std']).round(2)}\")\n",
    "print(f\"average_deviation_rate: {np.mean(results['average_deviation_rate_mean']).round(2)} +/- {np.mean(results['average_deviation_rate_std']).round(2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be observed that after 50,000 episodes of training, the model performs well on average across various randomised initial conditions, achieving Success Rate of 100, low Average Steps, high Average Reward and very marginal Average Deviation Rate from Optimal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Visualisation\n",
    "\n",
    "The visualisation phase is implemented using the `matplotlib` library with the `TkAgg` backend, allowing for interactive and animated representations of the agent's behaviour in the grid world environment. This visualisation aims to show the performance of agents with different levels of training, assess their generalizability, and visually present the learning progress.\n",
    "\n",
    "##### **Key components**\n",
    "\n",
    "1. **Environment initialisation**:\n",
    "\n",
    "The `env.reset()` function initialises the environment for each new episode, randomly setting the initial positions of the agent and item, preparing for a new simulation. It also establishes initial values for `state`, `done`, `episode_steps`, and `episode_reward`.\n",
    "\n",
    "2. **Initial setup**:\n",
    "\n",
    "Initial agent, item and target positions are printed, which provides context for the observer and serves as a benchmark for evaluating the agent's performance. \n",
    "\n",
    "3. **Visualisation setup**:\n",
    "\n",
    "Functions like `ListedColormap()`, `plt.subplots()`, `ax.set_xticks()`, `ax.set_yticks()`, and `ax.grid()` are used to create and configure the figure object. Custom color maps and grid lines are set up to enhance visual clarity. The legend explains different grid states:\n",
    "\n",
    "- Letter `A` with Green backgroun: Agent\n",
    "- Letter `I` with Red background: Item\n",
    "- Letter `T` with Gray background: Target location\n",
    "- Text `A+I` with Cyan background: Agent carrying the item\n",
    "- Text `A at T (No I)` with Magenta backgroun: Agent at target location without the item\n",
    "- Text `A+I at T` with Orange background: Agent at target location with the item\n",
    "\n",
    "4. **Animation function**:\n",
    "\n",
    "The internal function `animate(i)` updates each frame of the visualisation. It calls `agent.choose_action(state)` and `env.step(action)` to show the agent's real-time decision-making process. It uses `ax.imshow()` to update the grid state and `ax.text()` to add annotations for different elements (agent, item, target). The function employs complex conditional logic to update grid states, reflecting different scenarios (e.g., agent carrying item, reaching target). It also prints detailed step information for in-depth analysis.\n",
    "\n",
    "5. **Animation creation and display**:\n",
    "\n",
    "The visualisation process is implemented using `FuncAnimation()` to create an animated representation of the agent's behavior. This animation is displayed using `plt.show()`. To ensure the visualisation remains manageable and informative, we use a maximum step limit `(max_steps=25)`, which serves three crucial purposes:\n",
    "\n",
    "- It prevents the visualisation from running indefinitely if the agent is stuck in a loop.\n",
    "- It simulates real-world constraints where tasks often have time or resource limitations.\n",
    "- It provides a clear metric for improvement: as training progresses, the agent should complete the task within this limit more consistently.\n",
    "\n",
    "**Two possible scenarios:**<br>\n",
    "\n",
    "1. Task Not Completed (Failure Case):\n",
    "\n",
    "If the maximum step limit is reached without task completion:\n",
    "A `red` text annotation appears on the plot: \"Failed to complete within `max_steps` step limit!\"\n",
    "\n",
    "2. Task Completed Successfully:\n",
    "\n",
    "A `blue` text annotation is added to the plot: \"Successfully completed the task with deviation from the optimal path by `deviation` step(s)!\"\n",
    "\n",
    "After each visulisation, comprehensive summary is printed, detailing:\n",
    "\n",
    "- Number of steps taken\n",
    "- Optimal step count\n",
    "- Total reward accumulated\n",
    "- Deviation from the optimal path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to visualise one episode using the trained agent\n",
    "def visualise_episode(agent, env, cumulative_episodes, interval=500, max_steps=25):\n",
    "    # Reset the environment to start a new episode\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    episode_steps = 0\n",
    "    episode_reward = 0\n",
    "\n",
    "    # Capture initial positions for printing\n",
    "    initial_agent_location = state[0]\n",
    "    initial_item_location = state[1]\n",
    "    drop_off_location = env.target_location\n",
    "\n",
    "    # Calculate theoretical shortest path or optimal steps\n",
    "    optimal_steps_to_item = manhattan_distance(initial_agent_location, initial_item_location)\n",
    "    optimal_steps_to_target = manhattan_distance(initial_item_location, drop_off_location)\n",
    "    optimal_steps = optimal_steps_to_item + optimal_steps_to_target\n",
    "    \n",
    "    # Print the initial locations and episode information\n",
    "    print(f\"Initial Agent Location: {initial_agent_location}\")\n",
    "    print(f\"Initial Item Location (A): {initial_item_location}\")\n",
    "    print(f\"Drop-Off Location (B): {drop_off_location}\")\n",
    "\n",
    "    # Define a custom colormap\n",
    "    # 0 - white (grid face), 1 - green (agent), 2 - red (item), 3 - gray (target), 4 - cyan (agent with item),\n",
    "    # 5 - megenta (agent at the target without item), 6 - orange (agent with item at the target)\n",
    "    cmap = ListedColormap(['white', 'green', 'red', 'gray', 'cyan', 'magenta', 'orange'])\n",
    "\n",
    "    # Create the figure for visualisation\n",
    "    fig, ax = plt.subplots(figsize=(9, 6))\n",
    "    ax.set_xticks(np.arange(-0.5, env.size, 1))\n",
    "    ax.set_yticks(np.arange(-0.5, env.size, 1))\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.grid(True, color='black')  # Set grid lines to black\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "    # Set the background color to white\n",
    "    ax.set_facecolor('white')\n",
    "\n",
    "    # Add a title to the figure\n",
    "    fig.suptitle(f'Grid World - Trained {cumulative_episodes} Episodes', fontsize=16)\n",
    "\n",
    "    # Define the legend patches\n",
    "    legend_patches = [\n",
    "        mpatches.Patch(color='green', label='A - Agent'),\n",
    "        mpatches.Patch(color='red', label='I - Item'),\n",
    "        mpatches.Patch(color='gray', label='T - Target'),\n",
    "        mpatches.Patch(color='cyan', label='A+I'),\n",
    "        mpatches.Patch(color='magenta', label='A at T (No I)'),\n",
    "        mpatches.Patch(color='orange', label='A+I at T'),\n",
    "    ]\n",
    "\n",
    "    # Animate the grid world for each step in the episode\n",
    "    def animate(i):\n",
    "        # Access the nonlocal variables to update them\n",
    "        nonlocal state, episode_steps, done, episode_reward\n",
    "\n",
    "        # Display the initial state before starting the episode\n",
    "        if i == 0:\n",
    "            agent_pos, item_pos, has_item = state\n",
    "\n",
    "            grid = np.zeros((env.size, env.size))\n",
    "            grid[agent_pos] = 1\n",
    "            grid[item_pos] = 2\n",
    "            grid[env.target_location] = 3\n",
    "\n",
    "            ax.imshow(grid, cmap=cmap, vmin=0, vmax=6)\n",
    "\n",
    "            # Annotate the grid with labels but no color changes\n",
    "            for (j, i), label in np.ndenumerate(grid):\n",
    "                if label == 1: # Agent location only\n",
    "                    ax.text(i, j, 'A', ha='center', va='center', color='black', fontsize=11, fontweight='bold')\n",
    "                elif label == 2: # Item location only\n",
    "                    ax.text(i, j, 'I', ha='center', va='center', color='black', fontsize=11, fontweight='bold')\n",
    "                elif label == 3: # Target location only\n",
    "                    ax.text(i, j, 'T', ha='center', va='center', color='black', fontsize=11, fontweight='bold')\n",
    "            \n",
    "            # Reapply the legend after clearing\n",
    "            ax.legend(handles=legend_patches, loc='center right', bbox_to_anchor=(1.36, 0.85), fontsize='11')\n",
    "\n",
    "            return\n",
    "\n",
    "        # Continue the episode if the task is not finished\n",
    "        if not done:\n",
    "            # Select the action and perform the step in the environment\n",
    "            action = agent.choose_action(state)\n",
    "            next_state, reward, done = env.step(action)\n",
    "\n",
    "            episode_steps += 1\n",
    "            episode_reward += reward\n",
    "            state = next_state\n",
    "\n",
    "            # Print the step details\n",
    "            print(f\"Step {episode_steps}: Action = {action}, Reward = {reward}, New State = {next_state}\")\n",
    "\n",
    "            # Create the grid to visualise\n",
    "            grid = np.zeros((env.size, env.size))\n",
    "            agent_pos, item_pos, has_item = next_state\n",
    "\n",
    "            # Update the grid colors based on the current state\n",
    "            if not has_item and agent_pos != env.target_location:\n",
    "                grid[agent_pos] = 1\n",
    "                grid[item_pos] = 2\n",
    "                grid[env.target_location] = 3\n",
    "            elif not has_item and agent_pos == env.target_location:\n",
    "                grid[item_pos] = 2\n",
    "                grid[env.target_location] = 5\n",
    "            elif has_item and agent_pos != env.target_location:\n",
    "                grid[agent_pos] = 4\n",
    "                grid[env.target_location] = 3\n",
    "            elif has_item and agent_pos == env.target_location:\n",
    "                grid[env.target_location] = 6\n",
    "\n",
    "            ax.clear()\n",
    "            ax.imshow(grid, cmap=cmap, vmin=0, vmax=6)\n",
    "\n",
    "            # Reapply grid lines and labels after clearing\n",
    "            ax.set_xticks(np.arange(-0.5, env.size, 1))\n",
    "            ax.set_yticks(np.arange(-0.5, env.size, 1))\n",
    "            ax.set_xticklabels([])\n",
    "            ax.set_yticklabels([])\n",
    "            ax.grid(True, color='black')  # Set grid lines to black\n",
    "            ax.set_facecolor('white')  # Set background color to white\n",
    "\n",
    "            # Annotate the grid with labels but no color changes\n",
    "            for (j, i), label in np.ndenumerate(grid):\n",
    "                if label == 1: # Agent location only\n",
    "                    ax.text(i, j, 'A', ha='center', va='center', color='black', fontsize=11, fontweight='bold')\n",
    "                elif label == 2: # Item location only\n",
    "                    ax.text(i, j, 'I', ha='center', va='center', color='black', fontsize=11, fontweight='bold')\n",
    "                elif label == 3: # Target location only\n",
    "                    ax.text(i, j, 'T', ha='center', va='center', color='black', fontsize=11, fontweight='bold')\n",
    "                elif label == 4: # Agent location with item\n",
    "                    ax.text(i, j, 'A+I', ha='center', va='center', color='black', fontsize=11, fontweight='bold')\n",
    "                elif label == 5: # Target location with agent but without item\n",
    "                    ax.text(i, j, 'A at T (No I)', ha='center', va='center', color='black', fontsize=11, fontweight='bold')\n",
    "                elif label == 6: # Target location with agent and item\n",
    "                    ax.text(i, j, 'A+I at T', ha='center', va='center', color='black', fontsize=11, fontweight='bold')\n",
    "\n",
    "            # Reapply the legend after clearing\n",
    "            ax.legend(handles=legend_patches, loc='center right', bbox_to_anchor=(1.36, 0.85), fontsize='11')\n",
    "\n",
    "        # Stop the animation if the task is finished or the maximum steps are reached\n",
    "        if done or episode_steps == max_steps:  \n",
    "            deviation = episode_steps - optimal_steps\n",
    "            if episode_steps == max_steps:\n",
    "                print(f\"*** After {cumulative_episodes} episodes of training, agent did not complete the task within {max_steps} steps.\\n\")\n",
    "                # Annotate the \"Failed\" case on the plot\n",
    "                ax.text(0.5, 0.5, f'Failed to complete within {max_steps} step limit !', \n",
    "                        ha='center', va='center', transform=ax.transAxes, \n",
    "                        fontsize=20, color='red', fontweight='bold',\n",
    "                        bbox=dict(facecolor='white', alpha=0.8, edgecolor='red'))\n",
    "            elif done:\n",
    "                # Print the summary of the episode\n",
    "                # Annotate the \"Successful\" case on the plot\n",
    "                ax.text(0.5, 0.5, f'Successfully completed the task with\\n deviation from the optimal path by {deviation} step(s) !'.format(episode_steps),\n",
    "                        ha='center', va='center', transform=ax.transAxes, \n",
    "                        fontsize=20, color='blue', fontweight='bold',\n",
    "                        bbox=dict(facecolor='white', alpha=0.8, edgecolor='blue'))\n",
    "                print(f\"*** After {cumulative_episodes} episodes of training, agent completed the task.\")\n",
    "                print(f\"Summary: Steps = {episode_steps} (Optimal Steps = {optimal_steps}), Total Reward = {episode_reward}, Deviation from Optimal: {deviation}\\n\")\n",
    "\n",
    "            anim.event_source.stop()  # Stop the animation when done\n",
    "            plt.draw()  # Force a draw of the current figure to ensure the last frame is rendered\n",
    "\n",
    "            plt.pause(2)  # Short pause to ensure the rendering occurs\n",
    "            plt.close(fig)  # Automatically close the figure window\n",
    "\n",
    "    # Create the animation\n",
    "    anim = FuncAnimation(fig, animate, interval=interval, frames=100) \n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Examples of effects of different training episodes**\n",
    "\n",
    "We use random initialisations for each test to evaluate the agent's ability to generalize. By randomly setting the initial positions of the agent and item for each visualisation, we ensure that the agent's performance is tested across various scenarios, not just those it encountered during training. This approach helps assess whether the agent has learned general strategies or merely memorized specific paths.\n",
    "\n",
    "Progressive improvement with increased training:\n",
    "\n",
    "As the number of training episodes increases, we observe a clear progression in the agent's performance:\n",
    "\n",
    "- Exploratory stage (~ 100 episodes):\n",
    "\n",
    "The agent is in the initial phase, exploring the environment with minimal learned behavior. The agent often fails to complete the task within the maximum step limit (25 steps). Movements appear random or inefficient, indicating insufficient learning.\n",
    "\n",
    "- Adaptive stage (~ 500 episodes):\n",
    "\n",
    "The agent begins to adapt to the environment, showing early signs of learning but with inconsistent performance.  It might complete simpler configurations but fail in more complex scenarios.\n",
    "\n",
    "- Proficient stage (~ 1000 episodes):\n",
    "\n",
    "The agent is now more proficient, often completing tasks, though not always optimally. It shows more purposeful movements, suggesting improved learning.\n",
    "\n",
    "- Optimising stage (~ 2500 episodes):\n",
    "\n",
    "The agent is refining its strategies, consistently completing tasks with greater efficiency and fewer errors. Deviations from the optimal steps are smaller and less frequent.<br>\n",
    "\n",
    "- Mastery stage (~ 5000 episodes):\n",
    "\n",
    "The agent demonstrates mastery, achieving tasks with high efficiency and minimal deviations from the optimal steps. It efficiently navigates to the item and then to the target location, demonstrating well-developed strategies. The performance across random initialisations is consistently high, indicating good generalisability.\n",
    "\n",
    "This visualisation approach demonstrates the gradual improvement in the agent's performance across a wider range of training episodes. It highlights the agent's ability to generalise learned strategies to unseen situations, demonstrating the progression from failing to complete the task, to completing it sub-optimally, and finally to near-optimal completion across random scenarios. This comprehensive view allows us to observe the improvements at each stage of training, providing insights into the learning dynamics of the Q-learning algorithm in this grid world environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- After 100 Training Episodes Test Visualisation and Summary---\n",
      "Initial Agent Location: (4, 1)\n",
      "Initial Item Location (A): (3, 4)\n",
      "Drop-Off Location (B): (4, 4)\n",
      "Step 1: Action = north, Reward = -1, New State = ((3, 1), (3, 4), False)\n",
      "Step 2: Action = north, Reward = -1, New State = ((2, 1), (3, 4), False)\n",
      "Step 3: Action = east, Reward = -1, New State = ((2, 2), (3, 4), False)\n",
      "Step 4: Action = south, Reward = -1, New State = ((3, 2), (3, 4), False)\n",
      "Step 5: Action = north, Reward = -1, New State = ((2, 2), (3, 4), False)\n",
      "Step 6: Action = east, Reward = -1, New State = ((2, 3), (3, 4), False)\n",
      "Step 7: Action = south, Reward = -1, New State = ((3, 3), (3, 4), False)\n",
      "Step 8: Action = south, Reward = -1, New State = ((4, 3), (3, 4), False)\n",
      "Step 9: Action = west, Reward = -1, New State = ((4, 2), (3, 4), False)\n",
      "Step 10: Action = north, Reward = -1, New State = ((3, 2), (3, 4), False)\n",
      "Step 11: Action = west, Reward = -1, New State = ((3, 1), (3, 4), False)\n",
      "Step 12: Action = south, Reward = -1, New State = ((4, 1), (3, 4), False)\n",
      "Step 13: Action = west, Reward = -1, New State = ((4, 0), (3, 4), False)\n",
      "Step 14: Action = north, Reward = -1, New State = ((3, 0), (3, 4), False)\n",
      "Step 15: Action = east, Reward = -1, New State = ((3, 1), (3, 4), False)\n",
      "Step 16: Action = north, Reward = -1, New State = ((2, 1), (3, 4), False)\n",
      "Step 17: Action = west, Reward = -1, New State = ((2, 0), (3, 4), False)\n",
      "Step 18: Action = east, Reward = -1, New State = ((2, 1), (3, 4), False)\n",
      "Step 19: Action = south, Reward = -1, New State = ((3, 1), (3, 4), False)\n",
      "Step 20: Action = north, Reward = -1, New State = ((2, 1), (3, 4), False)\n",
      "Step 21: Action = east, Reward = -1, New State = ((2, 2), (3, 4), False)\n",
      "Step 22: Action = south, Reward = -1, New State = ((3, 2), (3, 4), False)\n",
      "Step 23: Action = south, Reward = -1, New State = ((4, 2), (3, 4), False)\n",
      "Step 24: Action = west, Reward = -1, New State = ((4, 1), (3, 4), False)\n",
      "Step 25: Action = north, Reward = -1, New State = ((3, 1), (3, 4), False)\n",
      "*** After 100 episodes of training, agent did not complete the task within 25 steps.\n",
      "\n",
      "--- After 500 Training Episodes Test Visualisation and Summary---\n",
      "Initial Agent Location: (0, 2)\n",
      "Initial Item Location (A): (1, 0)\n",
      "Drop-Off Location (B): (4, 4)\n",
      "Step 1: Action = south, Reward = -1, New State = ((1, 2), (1, 0), False)\n",
      "Step 2: Action = east, Reward = -1, New State = ((1, 3), (1, 0), False)\n",
      "Step 3: Action = east, Reward = -1, New State = ((1, 4), (1, 0), False)\n",
      "Step 4: Action = west, Reward = -1, New State = ((1, 3), (1, 0), False)\n",
      "Step 5: Action = east, Reward = -1, New State = ((1, 4), (1, 0), False)\n",
      "Step 6: Action = west, Reward = -1, New State = ((1, 3), (1, 0), False)\n",
      "Step 7: Action = east, Reward = -1, New State = ((1, 4), (1, 0), False)\n",
      "Step 8: Action = west, Reward = -1, New State = ((1, 3), (1, 0), False)\n",
      "Step 9: Action = east, Reward = -1, New State = ((1, 4), (1, 0), False)\n",
      "Step 10: Action = west, Reward = -1, New State = ((1, 3), (1, 0), False)\n",
      "Step 11: Action = east, Reward = -1, New State = ((1, 4), (1, 0), False)\n",
      "Step 12: Action = west, Reward = -1, New State = ((1, 3), (1, 0), False)\n",
      "Step 13: Action = east, Reward = -1, New State = ((1, 4), (1, 0), False)\n",
      "Step 14: Action = west, Reward = -1, New State = ((1, 3), (1, 0), False)\n",
      "Step 15: Action = east, Reward = -1, New State = ((1, 4), (1, 0), False)\n",
      "Step 16: Action = west, Reward = -1, New State = ((1, 3), (1, 0), False)\n",
      "Step 17: Action = east, Reward = -1, New State = ((1, 4), (1, 0), False)\n",
      "Step 18: Action = west, Reward = -1, New State = ((1, 3), (1, 0), False)\n",
      "Step 19: Action = east, Reward = -1, New State = ((1, 4), (1, 0), False)\n",
      "Step 20: Action = west, Reward = -1, New State = ((1, 3), (1, 0), False)\n",
      "Step 21: Action = east, Reward = -1, New State = ((1, 4), (1, 0), False)\n",
      "Step 22: Action = west, Reward = -1, New State = ((1, 3), (1, 0), False)\n",
      "Step 23: Action = east, Reward = -1, New State = ((1, 4), (1, 0), False)\n",
      "Step 24: Action = west, Reward = -1, New State = ((1, 3), (1, 0), False)\n",
      "Step 25: Action = east, Reward = -1, New State = ((1, 4), (1, 0), False)\n",
      "*** After 500 episodes of training, agent did not complete the task within 25 steps.\n",
      "\n",
      "--- After 1000 Training Episodes Test Visualisation and Summary---\n",
      "Initial Agent Location: (4, 1)\n",
      "Initial Item Location (A): (1, 2)\n",
      "Drop-Off Location (B): (4, 4)\n",
      "Step 1: Action = west, Reward = -1, New State = ((4, 0), (1, 2), False)\n",
      "Step 2: Action = north, Reward = -1, New State = ((3, 0), (1, 2), False)\n",
      "Step 3: Action = east, Reward = -1, New State = ((3, 1), (1, 2), False)\n",
      "Step 4: Action = west, Reward = -1, New State = ((3, 0), (1, 2), False)\n",
      "Step 5: Action = east, Reward = -1, New State = ((3, 1), (1, 2), False)\n",
      "Step 6: Action = west, Reward = -1, New State = ((3, 0), (1, 2), False)\n",
      "Step 7: Action = east, Reward = -1, New State = ((3, 1), (1, 2), False)\n",
      "Step 8: Action = west, Reward = -1, New State = ((3, 0), (1, 2), False)\n",
      "Step 9: Action = east, Reward = -1, New State = ((3, 1), (1, 2), False)\n",
      "Step 10: Action = west, Reward = -1, New State = ((3, 0), (1, 2), False)\n",
      "Step 11: Action = east, Reward = -1, New State = ((3, 1), (1, 2), False)\n",
      "Step 12: Action = west, Reward = -1, New State = ((3, 0), (1, 2), False)\n",
      "Step 13: Action = east, Reward = -1, New State = ((3, 1), (1, 2), False)\n",
      "Step 14: Action = west, Reward = -1, New State = ((3, 0), (1, 2), False)\n",
      "Step 15: Action = east, Reward = -1, New State = ((3, 1), (1, 2), False)\n",
      "Step 16: Action = west, Reward = -1, New State = ((3, 0), (1, 2), False)\n",
      "Step 17: Action = east, Reward = -1, New State = ((3, 1), (1, 2), False)\n",
      "Step 18: Action = west, Reward = -1, New State = ((3, 0), (1, 2), False)\n",
      "Step 19: Action = east, Reward = -1, New State = ((3, 1), (1, 2), False)\n",
      "Step 20: Action = west, Reward = -1, New State = ((3, 0), (1, 2), False)\n",
      "Step 21: Action = east, Reward = -1, New State = ((3, 1), (1, 2), False)\n",
      "Step 22: Action = west, Reward = -1, New State = ((3, 0), (1, 2), False)\n",
      "Step 23: Action = east, Reward = -1, New State = ((3, 1), (1, 2), False)\n",
      "Step 24: Action = west, Reward = -1, New State = ((3, 0), (1, 2), False)\n",
      "Step 25: Action = east, Reward = -1, New State = ((3, 1), (1, 2), False)\n",
      "*** After 1000 episodes of training, agent did not complete the task within 25 steps.\n",
      "\n",
      "--- After 2500 Training Episodes Test Visualisation and Summary---\n",
      "Initial Agent Location: (3, 2)\n",
      "Initial Item Location (A): (0, 1)\n",
      "Drop-Off Location (B): (4, 4)\n",
      "Step 1: Action = west, Reward = -1, New State = ((3, 1), (0, 1), False)\n",
      "Step 2: Action = north, Reward = -1, New State = ((2, 1), (0, 1), False)\n",
      "Step 3: Action = north, Reward = -1, New State = ((1, 1), (0, 1), False)\n",
      "Step 4: Action = north, Reward = -1, New State = ((0, 1), (0, 1), True)\n",
      "Step 5: Action = east, Reward = -1, New State = ((0, 2), (0, 1), True)\n",
      "Step 6: Action = east, Reward = -1, New State = ((0, 3), (0, 1), True)\n",
      "Step 7: Action = south, Reward = -1, New State = ((1, 3), (0, 1), True)\n",
      "Step 8: Action = east, Reward = -1, New State = ((1, 4), (0, 1), True)\n",
      "Step 9: Action = south, Reward = -1, New State = ((2, 4), (0, 1), True)\n",
      "Step 10: Action = south, Reward = -1, New State = ((3, 4), (0, 1), True)\n",
      "Step 11: Action = south, Reward = 100, New State = ((4, 4), (0, 1), True)\n",
      "*** After 2500 episodes of training, agent completed the task.\n",
      "Summary: Steps = 11 (Optimal Steps = 11), Total Reward = 90, Deviation from Optimal: 0\n",
      "\n",
      "--- After 5000 Training Episodes Test Visualisation and Summary---\n",
      "Initial Agent Location: (0, 1)\n",
      "Initial Item Location (A): (4, 3)\n",
      "Drop-Off Location (B): (4, 4)\n",
      "Step 1: Action = south, Reward = -1, New State = ((1, 1), (4, 3), False)\n",
      "Step 2: Action = south, Reward = -1, New State = ((2, 1), (4, 3), False)\n",
      "Step 3: Action = east, Reward = -1, New State = ((2, 2), (4, 3), False)\n",
      "Step 4: Action = south, Reward = -1, New State = ((3, 2), (4, 3), False)\n",
      "Step 5: Action = south, Reward = -1, New State = ((4, 2), (4, 3), False)\n",
      "Step 6: Action = east, Reward = -1, New State = ((4, 3), (4, 3), True)\n",
      "Step 7: Action = east, Reward = 100, New State = ((4, 4), (4, 3), True)\n",
      "*** After 5000 episodes of training, agent completed the task.\n",
      "Summary: Steps = 7 (Optimal Steps = 7), Total Reward = 94, Deviation from Optimal: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Visualise trained agent at different training levels\n",
    "\n",
    "# training progression list, e.g. first train for 100 episodes, then an additional 400 episodes\n",
    "# with a total of 500 episodes, then an addtional 500 episodes with a total of 1000 episodes, and so on\n",
    "# This is equivalent to test an agent at different training levels of 100, 500, 1000, 2500, and 5000 episodes.\n",
    "episodes_progression_list = [100, 400, 500, 1500, 2500]\n",
    "\n",
    "# Initialise the environment and agent\n",
    "env = GridWorld(size=5)\n",
    "actions = ['north', 'south', 'west', 'east']\n",
    "agent = QLearningAgent(actions)\n",
    "cumulative_episodes = 0\n",
    "\n",
    "for episode in episodes_progression_list:\n",
    "    cumulative_episodes += episode\n",
    "    train_agent(agent, env, episode)\n",
    "    print(f\"--- After {cumulative_episodes} Training Episodes Test Visualisation and Summary---\")\n",
    "    \n",
    "    visualise_episode(agent, env, cumulative_episodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Conclusion and Limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we successfully implemented a tabular Q-learning agent to navigate a grid world environment. The agent’s task was to locate a randomly positioned item and deliver it to a fixed target location, optimising the number of steps taken. Through iterative development and testing, we crafted a reward structure that effectively guided the agent’s learning process, allowing it to generalize across various initial conditions. The results demonstrate that our agent efficiently learned to perform the task, achieving high performance across different scenarios. The visualisations provided clearly illustrated the agent’s learning progression, further validating our approach.\n",
    "\n",
    "While our implementation effectively accomplished the task, several limitations were identified. The primary limitation is the scalability of tabular Q-learning. As the grid size increases, the state-action space expands exponentially, making it computationally intensive to manage the Q-table. This limitation also constrains the agent’s ability to learn in more complex environments that require finer granularity in state representation.\n",
    "\n",
    "Additionally, the agent’s learning efficiency is highly dependent on the reward structure and hyperparameters such as the learning rate and exploration strategy. Optimising these parameters requires extensive experimentation, which may not always be feasible in more complex environment settings.\n",
    "\n",
    "Moreover, the fixed nature of the grid world and the simplicity of the task do not fully reflect the challenges encountered in real-world applications. Addressing dynamic environments, obstacles, and more sophisticated task objectives would require advanced techniques, such as deep learning-based function approximation, which are beyond the scope of tabular Q-learning.\n",
    "\n",
    "Overall, this stage of the project laid a strong foundation for further exploration in reinforcement learning. The insights gained here will be invaluable as we transition to more complex environments and learning paradigms in subsequent stages. Our results underscore the potential of tabular Q-learning as a robust method for solving pathfinding and optimisation problems in grid-based environments, despite its limitations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Acknowledgement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We utilised ChatGPT (OpenAI, 2024) to summarise the code and review the grammar in our work. The output was subsequently adjusted to better align with our writing style."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenAI. (2024). ChatGPT (Version 1.2024.227) [Large language model]. https://chatgpt.com/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
